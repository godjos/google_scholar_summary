#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ•°æ®ç®¡ç†æ¨¡å—
è´Ÿè´£å¤„ç†å’Œå­˜å‚¨æ•°æ®
"""

import pandas as pd
import sqlite3
from typing import List, Dict, Optional, ContextManager
import json
import logging
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_manager.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class DataManager:
    """
    æ•°æ®ç®¡ç†å™¨ç±»
    """
    
    def __init__(self, database_path: str = "scholar_data.db"):
        """
        åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        
        Args:
            database_path: SQLiteæ•°æ®åº“è·¯å¾„
        """
        self.database_path = database_path
        self.init_database()
    
    def init_database(self):
        """
        åˆå§‹åŒ–æ•°æ®åº“è¡¨
        """
        with self._get_connection() as conn:
            cursor = conn.cursor()
            
            # åˆ›å»ºå·²å¤„ç†é‚®ä»¶è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS processed_emails (
                    email_id TEXT PRIMARY KEY,
                    receive_time TEXT,
                    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # åˆ›å»ºè®ºæ–‡ä¿¡æ¯è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS papers (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    title TEXT NOT NULL,
                    link TEXT UNIQUE,
                    abstract TEXT,
                    chinese_abstract TEXT,
                    highlights TEXT,
                    applications TEXT,
                    relevance_score INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')

            # æ£€æŸ¥relevance_scoreåˆ—æ˜¯å¦å­˜åœ¨(ç”¨äºæ—§è¡¨è¿ç§»)
            cursor.execute("PRAGMA table_info(papers)")
            columns = [column[1] for column in cursor.fetchall()]
            if "relevance_score" not in columns:
                logger.info("Updating database schema: adding relevance_score column")
                cursor.execute("ALTER TABLE papers ADD COLUMN relevance_score INTEGER DEFAULT 0")
            
            # åˆ›å»ºé‚®ä»¶ä¸è®ºæ–‡å…³è”è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS email_paper_relations (
                    email_id TEXT,
                    paper_link TEXT,
                    FOREIGN KEY (email_id) REFERENCES processed_emails (email_id),
                    FOREIGN KEY (paper_link) REFERENCES papers (link),
                    PRIMARY KEY (email_id, paper_link)
                )
            ''')
            
            conn.commit()
    
    def _get_connection(self) -> ContextManager[sqlite3.Connection]:
        """
        è·å–æ•°æ®åº“è¿æ¥çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        
        Returns:
            æ•°æ®åº“è¿æ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        """
        return sqlite3.connect(self.database_path)
    
    def format_paper_data(self, paper: Dict) -> Dict:
        """
        æ ¼å¼åŒ–è®ºæ–‡æ•°æ®ç”¨äºå¯¼å‡º
        """
        highlights = paper.get("highlights", [])
        if isinstance(highlights, list):
            highlights_str = "; ".join(highlights)
        else:
            highlights_str = str(highlights)
            
        applications = paper.get("applications", [])
        if isinstance(applications, list):
            applications_str = "; ".join(applications)
        else:
            applications_str = str(applications)
            
        return {
            "Title": paper.get("title", ""),
            "Link": paper.get("link", ""),
            "Abstract": paper.get("abstract", ""),
            "Chinese Abstract": paper.get("chinese_abstract", ""),
            "Highlights": highlights_str,
            "Applications": applications_str,
            "Relevance Score": paper.get("relevance_score", 0),
            "Receive Time": paper.get("receive_time", ""),
            "Created At": paper.get("created_at", "")
        }

    def is_email_processed(self, email_id: str) -> bool:
        """
        æ£€æŸ¥é‚®ä»¶æ˜¯å¦å·²å¤„ç†
        
        Args:
            email_id: é‚®ä»¶ID
            
        Returns:
            æ˜¯å¦å·²å¤„ç†
        """
        with self._get_connection() as conn:
            cursor = conn.cursor()
            
            cursor.execute('SELECT 1 FROM processed_emails WHERE email_id = ?', (email_id,))
            result = cursor.fetchone()
            
            return result is not None
    
    def mark_email_processed(self, email_id: str, receive_time: str = ""):
        """
        æ ‡è®°é‚®ä»¶ä¸ºå·²å¤„ç†
        
        Args:
            email_id: é‚®ä»¶ID
            receive_time: é‚®ä»¶æ¥æ”¶æ—¶é—´
        """
        with self._get_connection() as conn:
            cursor = conn.cursor()
            
            cursor.execute(
                'INSERT OR IGNORE INTO processed_emails (email_id, receive_time) VALUES (?, ?)', 
                (email_id, receive_time)
            )
            
            conn.commit()
    
    def is_paper_exists(self, paper_link: str) -> bool:
        """
        æ£€æŸ¥è®ºæ–‡æ˜¯å¦å·²å­˜åœ¨ (é€šè¿‡é“¾æ¥)
        
        Args:
            paper_link: è®ºæ–‡é“¾æ¥
            
        Returns:
            æ˜¯å¦å·²å­˜åœ¨
        """
        with self._get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('SELECT 1 FROM papers WHERE link = ?', (paper_link,))
            return cursor.fetchone() is not None

    def is_title_exists(self, title: str) -> bool:
        """
        æ£€æŸ¥è®ºæ–‡æ ‡é¢˜æ˜¯å¦å·²å­˜åœ¨ (å¿½ç•¥å¤§å°å†™)
        
        Args:
            title: è®ºæ–‡æ ‡é¢˜
            
        Returns:
            æ˜¯å¦å·²å­˜åœ¨
        """
        if not title:
            return False
            
        with self._get_connection() as conn:
            cursor = conn.cursor()
            # ä½¿ç”¨ LOWER() å‡½æ•°è¿›è¡Œä¸åŒºåˆ†å¤§å°å†™çš„æ¯”è¾ƒ
            # åŒæ—¶å»é™¤é¦–å°¾ç©ºæ ¼
            clean_title = title.strip().lower()
            cursor.execute('SELECT 1 FROM papers WHERE LOWER(title) = ?', (clean_title,))
            return cursor.fetchone() is not None

    def create_email_paper_relation(self, email_id: str, paper_link: str):
        """
        åˆ›å»ºé‚®ä»¶ä¸è®ºæ–‡çš„å…³è”å…³ç³»
        
        Args:
            email_id: é‚®ä»¶ID
            paper_link: è®ºæ–‡é“¾æ¥
        """
        with self._get_connection() as conn:
            cursor = conn.cursor()
            
            cursor.execute(
                'INSERT OR IGNORE INTO email_paper_relations (email_id, paper_link) VALUES (?, ?)',
                (email_id, paper_link)
            )
            
            conn.commit()

    def remove_duplicate_titles(self):
        """
        åˆ é™¤æ•°æ®åº“ä¸­é‡å¤æ ‡é¢˜çš„è®ºæ–‡ï¼Œä¿ç•™ç›¸å…³åº¦æœ€é«˜ï¼ˆæˆ–æœ€æ–°ï¼‰çš„è®°å½•
        ä½¿ç”¨æ ‡å‡†åŒ–æ ‡é¢˜ï¼ˆå°å†™+å»ç©ºæ ¼ï¼‰è¿›è¡Œæ¯”è¾ƒ
        """
        with self._get_connection() as conn:
            cursor = conn.cursor()
            try:
                # 1. æŸ¥æ‰¾é‡å¤çš„æ ‡é¢˜ (åŸºäºæ ‡å‡†åŒ–åçš„æ ‡é¢˜åˆ†ç»„)
                cursor.execute('''
                    SELECT LOWER(TRIM(title)), COUNT(*) 
                    FROM papers 
                    GROUP BY LOWER(TRIM(title)) 
                    HAVING COUNT(*) > 1
                ''')
                duplicate_groups = cursor.fetchall()
                
                if not duplicate_groups:
                    logger.info("æœªå‘ç°é‡å¤æ ‡é¢˜çš„è®ºæ–‡")
                    return

                logger.info(f"å‘ç° {len(duplicate_groups)} ç»„é‡å¤æ ‡é¢˜ï¼Œå¼€å§‹æ¸…ç†...")
                deleted_count = 0
                
                for group_row in duplicate_groups:
                    normalized_title = group_row[0]
                    
                    # è·å–è¯¥æ ‡å‡†åŒ–æ ‡é¢˜çš„æ‰€æœ‰è®°å½•
                    cursor.execute('''
                        SELECT id, link, relevance_score, title 
                        FROM papers 
                        WHERE LOWER(TRIM(title)) = ? 
                        ORDER BY relevance_score DESC, created_at DESC
                    ''', (normalized_title,))
                    records = cursor.fetchall()
                    
                    if not records:
                        continue
                        
                    # ä¿ç•™ç¬¬ä¸€æ¡ï¼ˆåˆ†æ•°æœ€é«˜/æœ€æ–°çš„ï¼‰ï¼Œåˆ é™¤å…¶ä»–çš„
                    keep_id = records[0][0]
                    keep_title = records[0][3]
                    to_delete = records[1:]
                    
                    # å¦‚æœæœ‰ä¸åŒçš„å¤§å°å†™å˜ä½“ï¼Œè®°å½•ä¸€ä¸‹æˆ‘ä»¬ä¿ç•™äº†å“ªä¸€ä¸ª
                    if len(to_delete) > 0:
                         logger.debug(f"ä¿ç•™: '{keep_title}' (ID: {keep_id}), åˆ é™¤ {len(to_delete)} ä¸ªå‰¯æœ¬")
                    
                    for row in to_delete:
                        del_id = row[0]
                        del_link = row[1]
                        
                        # åˆ é™¤å…³è”è¡¨ä¸­çš„è®°å½•
                        cursor.execute('DELETE FROM email_paper_relations WHERE paper_link = ?', (del_link,))
                        
                        # åˆ é™¤è®ºæ–‡è®°å½•
                        cursor.execute('DELETE FROM papers WHERE id = ?', (del_id,))
                        deleted_count += 1
                        
                conn.commit()
                logger.info(f"æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤äº† {deleted_count} ç¯‡é‡å¤è®ºæ–‡")
                
            except sqlite3.Error as e:
                logger.error(f"æ¸…ç†é‡å¤è®ºæ–‡æ—¶å‡ºé”™: {e}")
                conn.rollback()

    def save_paper(self, paper: Dict) -> bool:
        """
        ä¿å­˜å•ç¯‡è®ºæ–‡åˆ°æ•°æ®åº“
        
        Args:
            paper: è®ºæ–‡ä¿¡æ¯
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        with self._get_connection() as conn:
            cursor = conn.cursor()
            
            try:
                title = paper.get("title", "")
                link = paper.get("link", "")
                
                # æ£€æŸ¥è®ºæ–‡é“¾æ¥æ˜¯å¦å·²å­˜åœ¨
                cursor.execute('SELECT 1 FROM papers WHERE link = ?', (link,))
                if cursor.fetchone():
                    return False

                # æ£€æŸ¥è®ºæ–‡æ ‡é¢˜æ˜¯å¦å·²å­˜åœ¨ (å¿½ç•¥å¤§å°å†™)
                cursor.execute('SELECT 1 FROM papers WHERE LOWER(title) = ?', (title.strip().lower(),))
                if cursor.fetchone():
                    logger.info(f"è®ºæ–‡æ ‡é¢˜å·²å­˜åœ¨(å¿½ç•¥å¤§å°å†™): {title[:50]}... è·³è¿‡ä¿å­˜")
                    # å¦‚æœæ ‡é¢˜å­˜åœ¨ï¼Œæˆ‘ä»¬è¦ç¡®ä¿æ–°çš„é“¾æ¥(å¦‚æœæœ‰çš„è¯)ä¹Ÿä¸ä¼šè¢«å½“ä½œæ–°è®ºæ–‡å¤„ç†
                    # ä½†åœ¨è¿™é‡Œæˆ‘ä»¬åªæ˜¯è·³è¿‡ä¿å­˜ï¼Œä¸å»ºç«‹emailå…³è”ï¼Œæˆ–è€…å»ºç«‹?
                    # æŒ‰ç…§ç”¨æˆ·è¦æ±‚: "å¯¹äºæ•°æ®åº“ä¸­å­˜åœ¨çš„ç›¸åŒæ ‡é¢˜æ–‡ç« ç›´æ¥è·³è¿‡"
                    return False
                    
                # å°†åˆ—è¡¨è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²å­˜å‚¨
                highlights = paper.get("highlights", [])
                applications = paper.get("applications", [])
                
                highlights_str = json.dumps(highlights) if isinstance(highlights, list) else str(highlights)
                applications_str = json.dumps(applications) if isinstance(applications, list) else str(applications)
                
                cursor.execute('''
                    INSERT OR IGNORE INTO papers 
                    (title, link, abstract, chinese_abstract, highlights, applications, relevance_score)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    title,
                    link,
                    paper.get("abstract", ""),
                    paper.get("chinese_abstract", ""),
                    highlights_str,
                    applications_str,
                    paper.get("relevance_score", 0)
                ))
                
                conn.commit()
                return cursor.rowcount > 0
            except sqlite3.Error as e:
                logger.error(f"ä¿å­˜è®ºæ–‡æ—¶å‡ºé”™: {e}")
                return False
    
    def save_papers_batch(self, papers: List[Dict]):
        """
        æ‰¹é‡ä¿å­˜è®ºæ–‡åˆ°æ•°æ®åº“
        
        Args:
            papers: è®ºæ–‡ä¿¡æ¯åˆ—è¡¨
        """
        if not papers:
            return
            
        with self._get_connection() as conn:
            cursor = conn.cursor()
            
            try:
                # ä½¿ç”¨äº‹åŠ¡æ‰¹é‡æ’å…¥
                saved_count = 0
                
                # 1. é¢„å…ˆè·å–å·²å­˜åœ¨çš„é“¾æ¥
                existing_links = set()
                links = [p.get("link", "") for p in papers if p.get("link", "")]
                if links:
                    placeholders = ', '.join(['?'] * len(links))
                    cursor.execute(f'SELECT link FROM papers WHERE link IN ({placeholders})', links)
                    for row in cursor.fetchall():
                        existing_links.add(row[0])

                # 2. é¢„å…ˆè·å–å·²å­˜åœ¨çš„æ ‡é¢˜ (æ„å»ºæ ‡å‡†åŒ–æ ‡é¢˜é›†åˆ)
                existing_normalized_titles = set()
                titles = [p.get("title", "") for p in papers if p.get("title", "")]
                if titles:
                    # æˆ‘ä»¬éœ€è¦æ£€æŸ¥æ•°æ®åº“ä¸­æ‰€æœ‰ä¸è¿™æ‰¹æ ‡é¢˜"ç›¸ä¼¼"çš„æ ‡é¢˜
                    # æœ€ç®€å•çš„æ–¹æ³•æ˜¯ fetch all titles that match lower(...)
                    # ä½†ä¸ºäº†æ•ˆç‡ï¼Œæˆ‘ä»¬å¯ä»¥åªæŸ¥å‡ºæ‰€æœ‰å­˜åœ¨çš„ titleï¼Œæˆ–è€…é€ä¸ªæŸ¥?
                    # è€ƒè™‘åˆ°æ‰¹é‡å¯èƒ½åªæœ‰å‡ ç¯‡ï¼Œé€ä¸ªæŸ¥æˆ–è€… `LOWER(title) IN (...)` æ˜¯å¯è¡Œçš„
                    # SQLite çš„ LOWER(title) IN (...) å¯èƒ½æ— æ³•åˆ©ç”¨ç´¢å¼•ï¼Œä½†æ ‡é¢˜åˆ—é€šå¸¸æ²¡æœ‰ç´¢å¼•?
                    # è¿™é‡Œçš„ä¼˜åŒ–ç­–ç•¥ï¼šå…ˆæŸ¥å‡ºæ‰€æœ‰ç›¸å…³çš„ï¼Œæˆ–è€…è¿™é‡Œç›´æ¥ç”¨å¾ªç¯æ£€æŸ¥ç®—äº†ï¼Œåæ­£æ‰¹é‡ä¸å¤§
                    
                    # æ›´å¥½ï¼šä½¿ç”¨ set å­˜å‚¨æ‰€æœ‰æ ‡å‡†åŒ–åçš„æ ‡é¢˜
                    # å¦‚æœæ•°æ®é‡å¤§ï¼Œè¿™ä¸é«˜æ•ˆã€‚ä½†è€ƒè™‘åˆ°æ¯æ¬¡æ‰¹é‡åªæœ‰ 5-10 ç¯‡ï¼Œæˆ‘ä»¬å¯ä»¥æ¥å—?
                    # æˆ–è€…ï¼šSELECT LOWER(title) FROM papers WHERE LOWER(title) IN (lower(t1), lower(t2)...)
                    
                    lower_titles = [t.strip().lower() for t in titles]
                    placeholders = ', '.join(['?'] * len(lower_titles))
                    cursor.execute(f'SELECT LOWER(title) FROM papers WHERE LOWER(title) IN ({placeholders})', lower_titles)
                    for row in cursor.fetchall():
                        existing_normalized_titles.add(row[0])
                
                for paper in papers:
                    link = paper.get("link", "")
                    title = paper.get("title", "")
                    normalized_title = title.strip().lower()
                    
                    # æ£€æŸ¥è®ºæ–‡é“¾æ¥æ˜¯å¦å·²å­˜åœ¨
                    if link in existing_links:
                        continue
                        
                    # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦å·²å­˜åœ¨ (å¿½ç•¥å¤§å°å†™)
                    if normalized_title in existing_normalized_titles:
                        continue
                    
                    # å°†åˆ—è¡¨è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²å­˜å‚¨
                    highlights = paper.get("highlights", [])
                    applications = paper.get("applications", [])
                    
                    highlights_str = json.dumps(highlights) if isinstance(highlights, list) else str(highlights)
                    applications_str = json.dumps(applications) if isinstance(applications, list) else str(applications)
                    
                    cursor.execute('''
                        INSERT OR IGNORE INTO papers 
                        (title, link, abstract, chinese_abstract, highlights, applications, relevance_score)
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        title,
                        link,
                        paper.get("abstract", ""),
                        paper.get("chinese_abstract", ""),
                        highlights_str,
                        applications_str,
                        paper.get("relevance_score", 0)
                    ))
                    
                    if cursor.rowcount > 0:
                        saved_count += 1
                        existing_links.add(link)
                        existing_normalized_titles.add(normalized_title) # é˜²æ­¢åŒä¸€æ‰¹æ¬¡ä¸­æœ‰é‡å¤æ ‡é¢˜
                
                conn.commit()
                logger.info(f"æˆåŠŸæ‰¹é‡ä¿å­˜ {saved_count} ç¯‡æ–°è®ºæ–‡ï¼ˆè·³è¿‡ {len(papers) - saved_count} ç¯‡å·²å­˜åœ¨çš„è®ºæ–‡ï¼‰")
            except sqlite3.Error as e:
                logger.error(f"æ‰¹é‡ä¿å­˜è®ºæ–‡æ—¶å‡ºé”™: {e}")
                conn.rollback()
    
    def get_all_papers_with_receive_time(self) -> List[Dict]:
        """
        ä»æ•°æ®åº“è·å–æ‰€æœ‰è®ºæ–‡åŠæ¥æ”¶æ—¶é—´
        
        Returns:
            è®ºæ–‡ä¿¡æ¯åˆ—è¡¨ï¼ˆåŒ…å«æ¥æ”¶æ—¶é—´ï¼‰
        """
        with self._get_connection() as conn:
            cursor = conn.cursor()
            
            # æŸ¥è¯¢è®ºæ–‡ä¿¡æ¯åŠå…³è”çš„é‚®ä»¶æ¥æ”¶æ—¶é—´
            # æŒ‰ç›¸å…³åº¦é™åºï¼Œç„¶åæŒ‰æ”¶ä»¶æ—¶é—´é™åº (ç”¨æˆ·è¦æ±‚çš„"æ”¶é›†æ—¶é—´")
            # ä½¿ç”¨ GROUP BY p.id é¿å…å› å…³è”å¤šå°é‚®ä»¶è€Œå¯¼è‡´é‡å¤å‡ºç°
            cursor.execute('''
                SELECT p.title, p.link, p.abstract, p.chinese_abstract, p.highlights, p.applications, MAX(pe.receive_time), p.created_at, p.relevance_score
                FROM papers p
                LEFT JOIN email_paper_relations epr ON p.link = epr.paper_link
                LEFT JOIN processed_emails pe ON epr.email_id = pe.email_id
                GROUP BY p.id
                ORDER BY p.relevance_score DESC, MAX(pe.receive_time) DESC
            ''')
            
            rows = cursor.fetchall()
        
        papers = []
        for row in rows:
            # å°†JSONå­—ç¬¦ä¸²è½¬æ¢å›åˆ—è¡¨
            try:
                highlights = json.loads(row[4]) if row[4] else []
            except json.JSONDecodeError:
                highlights = []
                
            try:
                applications = json.loads(row[5]) if row[5] else []
            except json.JSONDecodeError:
                applications = []
            
            paper = {
                "title": row[0],
                "link": row[1],
                "abstract": row[2],
                "chinese_abstract": row[3],
                "highlights": highlights,
                "applications": applications,
                "receive_time": row[6] if row[6] else "",
                "created_at": row[7] if row[7] else "",
                "relevance_score": row[8] if row[8] is not None else 0
            }
            papers.append(paper)
        
        return papers
    
    def save_to_csv(self, papers: List[Dict], filename: str = "scholar_results.csv"):
        """
        å°†è®ºæ–‡ä¿¡æ¯ä¿å­˜åˆ°CSVæ–‡ä»¶
        
        Args:
            papers: è®ºæ–‡ä¿¡æ¯åˆ—è¡¨ï¼ˆæ­¤å‚æ•°å°†è¢«å¿½ç•¥ï¼‰
            filename: ä¿å­˜çš„æ–‡ä»¶å
        """
        try:
            # æ€»æ˜¯ä»æ•°æ®åº“è·å–æ‰€æœ‰è®ºæ–‡ï¼Œç¡®ä¿CSVæ–‡ä»¶ä¸æ•°æ®åº“åŒæ­¥
            all_papers = self.get_all_papers_with_receive_time()
            
            if not all_papers:
                logger.warning("æ²¡æœ‰è®ºæ–‡æ•°æ®å¯ä¿å­˜åˆ°CSVæ–‡ä»¶")
                return
            
            # æ ¼å¼åŒ–æ¯ç¯‡è®ºæ–‡çš„æ•°æ®
            formatted_papers = [self.format_paper_data(paper) for paper in all_papers]
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(formatted_papers)
            
            # ä¿å­˜ä¸ºCSVæ–‡ä»¶ï¼ˆè¦†ç›–æ¨¡å¼ï¼‰
            df.to_csv(filename, index=False, encoding="utf-8-sig")
            logger.info(f"æˆåŠŸå°† {len(all_papers)} ç¯‡è®ºæ–‡ä¿å­˜åˆ°CSVæ–‡ä»¶: {filename}")
        except Exception as e:
            logger.error(f"ä¿å­˜CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def save_to_excel(self, papers: List[Dict], filename: str = "scholar_results.xlsx"):
        """
        å°†è®ºæ–‡ä¿¡æ¯ä¿å­˜åˆ°Excelæ–‡ä»¶
        
        Args:
            papers: è®ºæ–‡ä¿¡æ¯åˆ—è¡¨ï¼ˆæ­¤å‚æ•°å°†è¢«å¿½ç•¥ï¼‰
            filename: ä¿å­˜çš„æ–‡ä»¶å
        """
        try:
            # æ€»æ˜¯ä»æ•°æ®åº“è·å–æ‰€æœ‰è®ºæ–‡ï¼Œç¡®ä¿Excelæ–‡ä»¶ä¸æ•°æ®åº“åŒæ­¥
            all_papers = self.get_all_papers_with_receive_time()
            
            if not all_papers:
                logger.warning("æ²¡æœ‰è®ºæ–‡æ•°æ®å¯ä¿å­˜åˆ°Excelæ–‡ä»¶")
                return
            
            # æ ¼å¼åŒ–æ¯ç¯‡è®ºæ–‡çš„æ•°æ®
            formatted_papers = [self.format_paper_data(paper) for paper in all_papers]
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(formatted_papers)
            
            # ä¿å­˜ä¸ºExcelæ–‡ä»¶
            df.to_excel(filename, index=False)
            logger.info(f"æˆåŠŸå°† {len(all_papers)} ç¯‡è®ºæ–‡ä¿å­˜åˆ°Excelæ–‡ä»¶: {filename}")
        except Exception as e:
            logger.error(f"ä¿å­˜Excelæ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def format_paper_data(self, paper: Dict) -> Dict:
        """
        æ ¼å¼åŒ–è®ºæ–‡æ•°æ®ç”¨äºå¯¼å‡º
        """
        highlights = paper.get("highlights", [])
        if isinstance(highlights, list):
            highlights_str = "; ".join(highlights)
        else:
            highlights_str = str(highlights)
            
        applications = paper.get("applications", [])
        if isinstance(applications, list):
            applications_str = "; ".join(applications)
        else:
            applications_str = str(applications)
            
        return {
            "Title": paper.get("title", ""),
            "Link": paper.get("link", ""),
            "Abstract": paper.get("abstract", ""),
            "Chinese Abstract": paper.get("chinese_abstract", ""),
            "Highlights": highlights_str,
            "Applications": applications_str,
            "Relevance Score": paper.get("relevance_score", 0),
            "Receive Time": paper.get("receive_time", ""),
            "Created At": paper.get("created_at", "")
        }

    def save_to_html(self, papers: List[Dict], filename: str = "scholar_results.html"):
        """
        å°†è®ºæ–‡ä¿¡æ¯ä¿å­˜åˆ°HTMLæ–‡ä»¶ï¼ˆé™æ€åˆ†é¡µæ¨¡å¼ï¼‰
        è§£å†³å•æ–‡ä»¶è¿‡å¤§æ— æ³•æ‰“å¼€çš„é—®é¢˜ã€‚
        ç»“æ„ï¼š
        - reports/index.html (ç¬¬1é¡µ + Dashboard)
        - reports/page_2.html (ç¬¬2é¡µ)
        - reports/page_3.html (ç¬¬3é¡µ)
        ...
        """
        try:
            # æ€»æ˜¯ä»æ•°æ®åº“è·å–æ‰€æœ‰è®ºæ–‡
            all_papers = self.get_all_papers_with_receive_time()
            
            if not all_papers:
                logger.warning("æ²¡æœ‰è®ºæ–‡æ•°æ®å¯ä¿å­˜åˆ°HTMLæ–‡ä»¶")
                return
            
            # è®¡ç®—ç»Ÿè®¡æ•°æ® (åªåœ¨é¦–é¡µæ˜¾ç¤ºæˆ–è®¡ç®—ä¸€æ¬¡)
            stats = self._calculate_stats(all_papers)
            
            total_papers = len(all_papers)
            page_size = 50
            total_pages = (total_papers + page_size - 1) // page_size
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            output_dir = os.path.dirname(filename)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir)
                logger.info(f"åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
                
            # æ¸…ç†æ—§çš„åˆ†é¡µæ–‡ä»¶ (å¯é€‰ï¼Œé˜²æ­¢æ··æ·†)
            # ...

            logger.info(f"å¼€å§‹ç”Ÿæˆé™æ€åˆ†é¡µHTMLæŠ¥å‘Šï¼Œå…± {total_papers} ç¯‡è®ºæ–‡ï¼Œåˆ† {total_pages} é¡µ...")
            
            base_name = os.path.basename(filename) # index.html
            
            for page in range(1, total_pages + 1):
                start_idx = (page - 1) * page_size
                end_idx = min(start_idx + page_size, total_papers)
                page_papers = all_papers[start_idx:end_idx]
                
                # ç¡®å®šå½“é¡µæ–‡ä»¶å
                if page == 1:
                    current_filename = filename
                else:
                    current_filename = os.path.join(output_dir, f"page_{page}.html")
                
                # ç”Ÿæˆé¡µé¢å†…å®¹
                html_content = self._generate_html_content(
                    papers=page_papers,
                    stats=stats,
                    current_page=page,
                    total_pages=total_pages,
                    total_papers=total_papers
                )
                
                with open(current_filename, 'w', encoding='utf-8') as f:
                    f.write(html_content)
                    
            logger.info(f"æˆåŠŸç”Ÿæˆåˆ†é¡µæŠ¥å‘Šï¼Œä¸»æ–‡ä»¶: {filename}, å…± {total_pages} é¡µ")
            
        except Exception as e:
            logger.error(f"ä¿å­˜HTMLæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

    def _calculate_stats(self, papers: List[Dict]) -> Dict:
        """è®¡ç®—Dashboardç»Ÿè®¡æ•°æ®"""
        total = len(papers)
        total_score = sum(p.get("relevance_score", 0) for p in papers)
        avg_score = round(total_score / total, 1) if total > 0 else 0
        high_rel = sum(1 for p in papers if p.get("relevance_score", 0) >= 8)
        
        from datetime import datetime
        today = datetime.now().strftime('%Y-%m-%d')
        recent = sum(1 for p in papers if p.get("receive_time", "").startswith(today))
        
        # åˆ†å¸ƒ
        dist = {"high": 0, "med": 0, "low": 0}
        for p in papers:
            s = p.get("relevance_score", 0)
            if s >= 8: dist["high"] += 1
            elif s >= 4: dist["med"] += 1
            else: dist["low"] += 1
            
        # è¶‹åŠ¿ (æœ€è¿‘14å¤©)
        date_counts = {}
        for p in papers:
            rt = p.get("receive_time", "")
            if rt:
                d = rt.split(' ')[0]
                date_counts[d] = date_counts.get(d, 0) + 1
        
        sorted_dates = sorted(date_counts.keys())[-14:]
        trend = {"labels": sorted_dates, "data": [date_counts[d] for d in sorted_dates]}
        
        return {
            "total": total,
            "avg_score": avg_score,
            "high_rel": high_rel,
            "recent": recent,
            "distribution": dist,
            "trend": trend
        }

    def _generate_html_content(self, papers: List[Dict], stats: Dict, current_page: int, total_pages: int, total_papers: int) -> str:
        """
        ç”Ÿæˆé™æ€é¡µé¢HTMLå†…å®¹ (Server-Side Rendering)
        """
        
        # 1. ç”Ÿæˆ Dashboard HTML (ä»…åœ¨ç¬¬ä¸€é¡µæ˜¾ç¤ºï¼Œæˆ–è€…æŠ˜å æ˜¾ç¤º)
        dashboard_html = ""
        if current_page == 1:
            dashboard_html = f"""
            <div class="dashboard">
                <div class="chart-card">
                    <div class="chart-title">ğŸ“Š å…³é”®æŒ‡æ ‡</div>
                    <div class="stats-grid">
                        <div class="stat-item"><div class="stat-value">{stats['total']}</div><div class="stat-label">æ€»è®ºæ–‡æ•°</div></div>
                        <div class="stat-item"><div class="stat-value">{stats['avg_score']}</div><div class="stat-label">å¹³å‡ç›¸å…³åº¦</div></div>
                        <div class="stat-item"><div class="stat-value">{stats['high_rel']}</div><div class="stat-label">å¼ºç›¸å…³(8+)</div></div>
                        <div class="stat-item"><div class="stat-value">{stats['recent']}</div><div class="stat-label">ä»Šæ—¥æ–°å¢</div></div>
                    </div>
                </div>
                <div class="chart-card">
                    <div class="chart-title">ğŸ¯ ç›¸å…³åº¦åˆ†å¸ƒ</div>
                    <canvas id="scoreChart"></canvas>
                </div>
                <div class="chart-card" style="grid-column: span 1 / -1;">
                    <div class="chart-title">ğŸ“… æ¯æ—¥æ”¶å½•è¶‹åŠ¿</div>
                    <canvas id="trendChart" height="80"></canvas>
                </div>
            </div>
            """
        
        # 2. ç”Ÿæˆè®ºæ–‡åˆ—è¡¨ HTML
        papers_html = ""
        for paper in papers:
            score = paper.get("relevance_score", 0)
            rel_class = 'low-relevance'
            if score >= 8: rel_class = 'high-relevance'
            elif score >= 4: rel_class = 'medium-relevance'
            
            highlights = paper.get("highlights", [])
            hl_html = "".join([f'<span class="tag">{h}</span>' for h in highlights]) if isinstance(highlights, list) else ""
            
            applications = paper.get("applications", [])
            app_html = "".join([f'<span class="tag app">{a}</span>' for a in applications]) if isinstance(applications, list) else ""
            
            chinese_abstract = ""
            if paper.get("chinese_abstract"):
                chinese_abstract = f'<div class="chinese-abstract"><strong>æ‘˜è¦:</strong> {paper.get("chinese_abstract")}</div>'
            
            papers_html += f"""
            <div class="paper-card {rel_class}">
                <div class="paper-header">
                    <h2 class="paper-title"><a href="{paper.get("link", "")}" target="_blank">{paper.get("title", "")}</a></h2>
                    <span class="relevance-badge">è¯„åˆ†: {score}</span>
                </div>
                <div class="paper-meta">
                    <span>ğŸ“… {paper.get("receive_time", "æœªçŸ¥")}</span>
                    <span>ğŸ“ {paper.get("created_at", "æœªçŸ¥")}</span>
                </div>
                {chinese_abstract}
                <div class="tags">{hl_html}</div>
                <div class="tags" style="margin-top:5px">{app_html}</div>
                <details style="margin-top:10px; color:var(--text-secondary); font-size:13px;">
                    <summary>åŸå§‹æ‘˜è¦</summary>
                    <p>{paper.get("abstract", "")}</p>
                </details>
            </div>
            """

        # 3. ç”Ÿæˆåˆ†é¡µå¯¼èˆª HTML
        pagination_html = '<div class="pagination">'
        
        # ä¸Šä¸€é¡µ
        if current_page > 1:
            prev_link = "index.html" if current_page == 2 else f"page_{current_page-1}.html"
            pagination_html += f'<a href="{prev_link}" class="page-link">ä¸Šä¸€é¡µ</a>'
        else:
            pagination_html += '<span class="page-link disabled">ä¸Šä¸€é¡µ</span>'
            
        # ç®€å•çš„é¡µç æ˜¾ç¤º (ä¼˜åŒ–ï¼šåªæ˜¾ç¤ºå‘¨å›´çš„é¡µç )
        start_p = max(1, current_page - 2)
        end_p = min(total_pages, current_page + 2)
        
        if start_p > 1:
            pagination_html += '<a href="index.html" class="page-link">1</a>'
            if start_p > 2: pagination_html += '<span class="page-sep">...</span>'
            
        for p in range(start_p, end_p + 1):
            if p == current_page:
                pagination_html += f'<span class="page-link active">{p}</span>'
            else:
                link = "index.html" if p == 1 else f"page_{p}.html"
                pagination_html += f'<a href="{link}" class="page-link">{p}</a>'
                
        if end_p < total_pages:
            if end_p < total_pages - 1: pagination_html += '<span class="page-sep">...</span>'
            pagination_html += f'<a href="page_{total_pages}.html" class="page-link">{total_pages}</a>'
            
        # ä¸‹ä¸€é¡µ
        if current_page < total_pages:
            pagination_html += f'<a href="page_{current_page+1}.html" class="page-link">ä¸‹ä¸€é¡µ</a>'
        else:
             pagination_html += '<span class="page-link disabled">ä¸‹ä¸€é¡µ</span>'
             
        pagination_html += f'<span style="margin-left:15px; color:#5f6368;">å…± {total_papers} ç¯‡</span></div>'

        # 4. æ³¨å…¥ Chart.js æ•°æ®è„šæœ¬ (ä»…ç¬¬ä¸€é¡µéœ€è¦)
        chart_script = ""
        if current_page == 1:
            chart_script = f"""
            <script>
                document.addEventListener('DOMContentLoaded', () => {{
                    const stats = {json.dumps(stats, ensure_ascii=False)};
                    
                    new Chart(document.getElementById('scoreChart'), {{
                        type: 'doughnut',
                        data: {{
                            labels: ['å¼ºç›¸å…³', 'ä¸­ç­‰', 'å¼±ç›¸å…³'],
                            datasets: [{{ 
                                data: [stats.distribution.high, stats.distribution.med, stats.distribution.low], 
                                backgroundColor: ['#ea4335', '#fbbc04', '#dadce0'] 
                            }}]
                        }},
                        options: {{ responsive: true, plugins: {{ legend: {{ position: 'right' }} }} }}
                    }});
                    
                    new Chart(document.getElementById('trendChart'), {{
                        type: 'bar',
                        data: {{
                            labels: stats.trend.labels,
                            datasets: [{{ 
                                label: 'æ”¶å½•æ•°é‡', 
                                data: stats.trend.data, 
                                backgroundColor: '#4285f4', 
                                borderRadius: 4 
                            }}]
                        }},
                        options: {{ responsive: true, scales: {{ y: {{ beginAtZero: true }} }} }}
                    }});
                }});
            </script>
            """

        return f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google Scholar æ±‡æ€» - ç¬¬ {current_page} é¡µ</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        :root {{ --primary-color: #4285f4; --secondary-color: #34a853; --bg-color: #f8f9fa; --card-bg: #ffffff; --text-primary: #202124; --text-secondary: #5f6368; --border-color: #dadce0; }}
        body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Arial, sans-serif; background-color: var(--bg-color); color: var(--text-primary); margin: 0; padding: 0; }}
        .container {{ max-width: 1400px; margin: 0 auto; padding: 20px; }}
        header {{ background-color: var(--card-bg); padding: 15px 0; box-shadow: 0 1px 3px rgba(0,0,0,0.1); position: sticky; top: 0; z-index: 100; margin-bottom: 20px; }}
        .header-content {{ max-width: 1400px; margin: 0 auto; padding: 0 20px; display: flex; justify-content: space-between; align-items: center; }}
        h1 {{ margin: 0; color: var(--primary-color); font-size: 22px; }}
        
        .dashboard {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin-bottom: 30px; }}
        .chart-card {{ background: var(--card-bg); padding: 20px; border-radius: 8px; box-shadow: 0 1px 2px rgba(60,64,67,0.3); }}
        .chart-title {{ font-size: 16px; font-weight: 600; margin-bottom: 15px; color: var(--text-secondary); }}
        .stats-grid {{ display: grid; grid-template-columns: repeat(2, 1fr); gap: 15px; }}
        .stat-item {{ text-align: center; padding: 10px; background: #f1f3f4; border-radius: 8px; }}
        .stat-value {{ font-size: 24px; font-weight: bold; color: var(--primary-color); }}
        .stat-label {{ font-size: 12px; color: var(--text-secondary); }}

        .paper-list {{ display: flex; flex-direction: column; gap: 20px; }}
        .paper-card {{ background-color: var(--card-bg); border-radius: 8px; padding: 20px; box-shadow: 0 1px 2px rgba(60,64,67,0.3); border-left: 5px solid transparent; }}
        .paper-card.high-relevance {{ border-left-color: #ea4335; }}
        .paper-card.medium-relevance {{ border-left-color: #fbbc04; }}
        .paper-card.low-relevance {{ border-left-color: #dadce0; }}
        .paper-header {{ display: flex; justify-content: space-between; align-items: flex-start; }}
        .paper-title {{ margin: 0 0 10px 0; font-size: 18px; color: var(--primary-color); }}
        .paper-title a {{ text-decoration: none; color: inherit; }}
        .paper-title a:hover {{ text-decoration: underline; }}
        .relevance-badge {{ padding: 2px 8px; border-radius: 12px; font-weight: bold; font-size: 12px; background: #f1f3f4; float: right; }}
        .high-relevance .relevance-badge {{ background-color: #fce8e6; color: #c5221f; }}
        .medium-relevance .relevance-badge {{ background-color: #fef7e0; color: #b06000; }}
        .paper-meta {{ font-size: 12px; color: var(--text-secondary); margin-bottom: 10px; display: flex; gap: 15px; }}
        .chinese-abstract {{ background-color: #f8f9fa; padding: 10px; margin: 10px 0; border-left: 4px solid var(--secondary-color); font-size: 14px; }}
        .tags {{ display: flex; flex-wrap: wrap; gap: 8px; margin-top: 5px; }}
        .tag {{ font-size: 12px; padding: 3px 10px; border-radius: 12px; background-color: #e8f0fe; color: #1967d2; }}
        .tag.app {{ background-color: #e6f4ea; color: #137333; }}

        .pagination {{ display: flex; justify-content: center; align-items: center; padding: 30px 0; gap: 5px; }}
        .page-link {{ padding: 8px 12px; border: 1px solid var(--border-color); background: var(--card-bg); border-radius: 4px; text-decoration: none; color: var(--text-primary); }}
        .page-link:hover {{ background: #f1f3f4; }}
        .page-link.active {{ background: var(--primary-color); color: white; border-color: var(--primary-color); }}
        .page-link.disabled {{ color: var(--text-secondary); cursor: not-allowed; background: #f1f3f4; }}
    </style>
</head>
<body>

<header>
    <div class="header-content">
        <h1>Google Scholar Summary <small>ç¬¬ {current_page} é¡µ</small></h1>
        <div style="font-size: 14px; color: var(--text-secondary);">å…± {total_papers} ç¯‡</div>
    </div>
</header>

<div class="container">
    {dashboard_html}
    
    <div class="paper-list">
        {papers_html}
    </div>
    
    {pagination_html}
</div>

{chart_script}

</body>
</html>
"""
